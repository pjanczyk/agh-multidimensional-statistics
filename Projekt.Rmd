---
title: "Statystyka Wielowymiarowa — Projekt"
author: "Piotr Janczyk, Miłosz Janowski"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(comment = '', echo = TRUE)
```

```{r}
library(leaps)
set.seed(1)
```


# Zbiór danych

Cechy:  

* `price` — price in US dollars (\$326–\$18,823)
* `carat` — weight of the diamond (0.2–5.01)
* `cut` — quality of the cut (_Fair_, _Good_, _Very Good_, _Premium_, _Ideal_)
* `color` — diamond colour, from _D_ (best) to _J_ (worst)
* `clarity` — a measurement of how clear the diamond is (_I1_ (worst), _SI2_, _SI1_, _VS2_, _VS1_, _VVS2_, _VVS1_, _IF_ (best))
* `x` — length in mm (0–10.74)
* `y` — width in mm (0–58.9)
* `z` — depth in mm (0–31.8)
* `depth` — total depth percentage = `z / mean(x, y)` = `2 * z / (x + y)` (43–79)
* `table` — width of top of diamond relative to widest point (43–95)

```{r}
diamonds <- read.csv("diamonds.csv", header = TRUE, stringsAsFactors = TRUE)
str(diamonds)
knitr::kable(head(diamonds))
```


# Przygotowanie zbioru danych
```{r}
# Usunięcie liczb porządkowych
diamonds$X <- NULL

# Posortowanie zmiennych typu factor
diamonds$color <- factor(diamonds$color,
                         levels = c("D", "E", "F", "G", "H", "I", "J"),
                         ordered = TRUE)

diamonds$clarity <- factor(diamonds$clarity,
                           levels = c("I1", "SI2", "SI1", "VS2", "VS1", "VVS2", "VVS1", "IF"),
                           ordered = TRUE)

diamonds$cut <- factor(diamonds$cut,
                       levels = c("Fair", "Good", "Very Good", "Premium", "Ideal"),
                       ordered = TRUE)

# Konwersja do zmiennych numerycznych
diamonds_num <- transform(diamonds,
                          color = as.numeric(color),
                          clarity = as.numeric(clarity),
                          cut = as.numeric(cut))
```

# Pomocnicze funkcje

```{r}
fancy_plot <- function (x, y, ...) {
  if (is.numeric(x)) {
    # Powiększenie danych na wykresie poprzez ukrycie daleko oddalonych skrajnych punktów
    xlim = quantile(x, c(0.001, 0.999))
    col = "#555555"
  } else {
    xlim = NULL
    col = "#cccccc"
  }

  plot(x = x, y = y, xlim = xlim, pch = 20, cex = 0.05, col = col, ...)
}
```


# Regresja jednokrotna

```{r}

single_linear_regression <- function (predictor, predictor_name) {
  predictor_num <- as.numeric(predictor)
  
  lm_fit <- lm(diamonds$price ~ predictor_num)
  #poly_fit <- lm(diamonds$price ~ poly(predictor_num, 3))
  
  fancy_plot(x = predictor,
             y = diamonds$price,
             main = sprintf("price / %s", predictor_name),
             xlab = predictor_name,
             ylab = "price ($)")
  
  abline(lm_fit, lwd = 2, col = "red")
  
  #grid <- seq(min(predictor_num), max(predictor_num), length.out = 100)

  #lines(x = grid,
  #      y = predict(poly_fit, list(predictor_num = grid), se.fit = TRUE)$fit,
  #      lwd = 2, col = "red")
}

single_linear_regression(diamonds$carat, "carat")
single_linear_regression(diamonds$cut, "cut")
single_linear_regression(diamonds$color, "color")
single_linear_regression(diamonds$clarity, "clarity")
single_linear_regression(diamonds$depth, "depth")
single_linear_regression(diamonds$depth + runif(nrow(diamonds), -0.05, 0.05), "depth (with random noise)")
single_linear_regression(diamonds$table, "table")
single_linear_regression(as.factor(round(diamonds$table)), "table (rounded to nearest integer)")
single_linear_regression(diamonds$x, "x")
single_linear_regression(diamonds$y, "y")
single_linear_regression(diamonds$x, "z")
```

# Podział na zbiór treningowy i testowy

```{r}
n <- nrow(diamonds)
train <- sample(1:n, n / 2)
test <- -train
```

# Regresja liniowa wielokrotna

```{r}
lm_fit <- lm(price ~ ., data = diamonds_num, subset = train)
summary(lm_fit)

lm_pred <- predict(lm_fit, diamonds_num[test,])

lm_mse <- mean((diamonds_num$price[test] - lm_pred) ^ 2)
lm_mse
```

# Wybór najlepszego podzbioru cech

```{r}
bs_fit <- regsubsets(price ~ ., data = diamonds_num, nvmax = Inf)
bs_fit_summary <- summary(bs_fit)
bs_fit_summary
```

### Kryterium BIC

```{r}
plot(bs_fit, scale = 'bic')
```

### Przy pomocy metody zbioru walidacyjnego

```{r}
predict.regsubsets <- function(object, newdata, id, ...) {
  model.formula <- as.formula(object$call[[2]])
  mat <- model.matrix(model.formula, newdata)
  coefs <- coef(object, id = id)
  mat[, names(coefs)] %*% coefs
}

bs_mse <- sapply(1:9, function(i) {
  pred <- predict(bs_fit, diamonds_num[test,], id = i)
  mean((diamonds_num$price[test] - pred) ^ 2)
})
bs_mse

plot(bs_mse, 
     xlab = "Liczba zmiennych", ylab = "MSE",
     col = "black", type = "b", pch = 20)
points(which.min(bs_mse), min(bs_mse), col = "red", pch = 9)
```

# Drzewo decyzyjne
```{r}
library(tree)
Cost <- factor(ifelse(diamonds$price <= 1000, "Cheap", ifelse(diamonds$price <= 10000, "Moderate", "Expansive")))
diamondsE <- data.frame(diamonds_num, Cost)

diamonds.tree <- tree(Cost ~ . - price, data = diamondsE, subset = train)
plot(diamonds.tree)
text(diamonds.tree, pretty = 0)
summary(diamonds.tree)

tree.class <- predict(diamonds.tree, newdata = diamondsE[test,], type = "class")
table(tree.class, diamondsE$Cost[test])
mean(tree.class != diamondsE$Cost[test])

```

# Regresja wielomianowa i naturalnymi funkcjami sklejanymi
```{r}
diamondsX <- diamonds[diamonds$x > 0, ]
fit.poly <- lm(price ~ poly(x, 3), data = diamondsX)
summary(fit.poly)

x.lims <- range(diamondsX$x)
x.grid <- seq(x.lims[1], x.lims[2])
pred.poly <- predict(fit.poly, list(x = x.grid), se.fit = TRUE)
se.bands <- cbind(pred.poly$fit + 2 * pred.poly$se.fit, 
                  pred.poly$fit - 2 * pred.poly$se.fit)
fit.smooth.cv <- smooth.spline(diamondsX$x, diamondsX$price)

fancy_plot(diamondsX$x, diamondsX$price, xlab = "x (mm)", ylab = "price ($)")
lines(x.grid, pred.poly$fit, col = "red", lwd = 2)
matlines(x.grid, se.bands, col = "red", lty = "dashed")
lines(fit.smooth.cv, col = "blue", lwd = 2)
```

# Regresja logistyczna GAM
```{r}
library(gam)
fit.gam.bf <- gam(I(price > 10000) ~ s(table, df = 5) + cut + clarity + color, data = diamonds, family = binomial)
summary(fit.gam.bf)
#par(mfrow = c(1,4))
plot(fit.gam.bf, col = "red")
```

